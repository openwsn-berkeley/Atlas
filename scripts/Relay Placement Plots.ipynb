{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../logs\\\\default_log_220215180248.json', '../logs\\\\default_log_220215180357.json', '../logs\\\\default_log_220215180816.json']\n"
     ]
    }
   ],
   "source": [
    "##################################### HELPER FUNCTIONS AND CONFIGURATIONS #########################################\n",
    "\n",
    "import seaborn as sns # for data visualization\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "import statistics\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "%matplotlib inline\n",
    "\n",
    "pp       =  pprint.PrettyPrinter(compact=True)\n",
    "\n",
    "LOGFILES =  glob.glob('../logs/default_log_*' )\n",
    "\n",
    "print(LOGFILES)\n",
    "\n",
    "#=== line colors and styles\n",
    "\n",
    "linestyles = {\n",
    "    #=======scenarios========\n",
    "    'empty'      :   'dotted',\n",
    "    'canonical'  :   'dashed',\n",
    "    'floorplan'  :  'dashdot',\n",
    "    #=======algorithms=======\n",
    "    #------exploration------- \n",
    "    'Atlas'      :    'solid',\n",
    "    #----relay placement-----\n",
    "    'Recovery'   :    'solid',\n",
    "    'SelfHealing':    'solid',\n",
    "    'Naive'      :    'solid',\n",
    "}\n",
    "\n",
    "linecolors = {\n",
    "    #=======scenarios==========\n",
    "    'empty'      :      'green',\n",
    "    'canonical'  :       'blue',\n",
    "    'floorplan'  :        'red',\n",
    "    #=======algorithms=========\n",
    "    #------exploration---------\n",
    "    'Atlas'      :  'royalblue',\n",
    "    #------relay placement-----\n",
    "    'Recovery'   :     'purple',\n",
    "    'SelfHealing':      'green',\n",
    "    'Naive'      :     'orange',\n",
    "     }\n",
    "\n",
    "#=== helper functions\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return (m, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '1']\n",
      "runNums: 3 TotalLines: 3\n"
     ]
    }
   ],
   "source": [
    "#=== gather data: group all run lines into one data file and create log with all runs\n",
    "\n",
    "lines = []\n",
    "log   = []\n",
    "logs  = []\n",
    "config_ids = []\n",
    "for logfile in LOGFILES:\n",
    "    with open(logfile,'r') as f:\n",
    "        for line in f:\n",
    "            lines += [json.loads(line)]\n",
    "            \n",
    "runNums    = 0\n",
    "\n",
    "for line in lines:        \n",
    "    if line['time'] == [1]:\n",
    "        runNums     += 1  \n",
    "        log.append(pd.DataFrame(logs))\n",
    "        config_ids.append(line['config ID'][0][-1][-1])\n",
    "        logs = []    \n",
    "    logs.append(line)\n",
    "log.append(pd.DataFrame(logs))\n",
    "log.pop(0)\n",
    "print(config_ids)\n",
    "print('runNums: {} TotalLines: {}'.format(runNums,len(log)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====== aggrigate data\n",
    "# we will calculate the confidence interval for:\n",
    "# 1. the PDR per robot per second for every specific configuration\n",
    "# 2. the mapping profile\n",
    "\n",
    "mapping_profiles = []\n",
    "\n",
    "for run_id,run in enumerate(log):\n",
    "    mapping_profile      = run['mapping profile']\n",
    "    config_id            = run['config ID'][0][-1][-1]\n",
    "    mapping_profile_data = {config_id :[mp[0] for mp in mapping_profile]}\n",
    "    \n",
    "    mapping_profiles.append(mapping_profile_data)\n",
    "    \n",
    "    # need to choose a common factor to aggregate data based on\n",
    "    # will go with configuration id\n",
    "    \n",
    "for config in config_ids:\n",
    "    globals()[f'mapping_profile_of_config_{config}'] = []\n",
    "\n",
    "for profile in mapping_profiles:\n",
    "    key = str(profile.keys())\n",
    "    config = key[-4]\n",
    "    globals()[f'mapping_profile_of_config_{config}'].append(profile[config])\n",
    "\n",
    "# for config in set(config_ids):\n",
    "#     data = globals()[f'mapping_profile_of_config_{config}']\n",
    "#     (m,h) = mean_confidence_interval(data)\n",
    "#     print(m,h)\n",
    "    \n",
    "\n",
    "#     for profile in mapping_profile:\n",
    "#         globals()[f'mapping_profile_{config_id}'].append(profile[0])\n",
    "#     print(mapping_profile_2)\n",
    "              \n",
    "#     for (k2,profiles) in v1.items():\n",
    "        \n",
    "#         maxlen  = max(df_0['time'])[0]\n",
    "#         ms      = []\n",
    "#         hs      = []\n",
    "#         for i in range(maxlen):\n",
    "#             l = []\n",
    "#             for p in profiles:\n",
    "#                 try:\n",
    "#                     l += [p[i]]\n",
    "#                 except IndexError:\n",
    "#                     pass\n",
    "#             (m,h) = mean_confidence_interval(l)\n",
    "#             ms += [m]\n",
    "#             hs += [h]\n",
    "#         data[k1][k2] = {\n",
    "#             'mean':                ms,\n",
    "#             'confidence_interval': hs,\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Violin Plot #############################################\n",
    "\n",
    "# want to create a panda dataframe for every simSetting\n",
    "# e.g 10 robots, empty floorplan, upper pdr threshold 0.9, lower pdr threshold 0.7 ...etc\n",
    "# every simSetting will have a unique identifier\n",
    "# lets say we have 100 runs per setting and have 3 settings\n",
    "# we will have 3 panda data frames, each with 100x (time-to-completion) lines\n",
    "# for every data frame we will find the confidence interval.\n",
    "# this data will be use all through out the notebook to create the plots.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Heatmap     #############################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Mapping Profile  ########################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runNums: 3 TotalLines: 1989\n"
     ]
    }
   ],
   "source": [
    "# #=== gather data: create a datafile per configuration\n",
    "# configIDs = set()\n",
    "# logs = []\n",
    "# log  = []\n",
    "# for logfile in LOGFILES:\n",
    "#     with open(logfile,'r') as f:\n",
    "#         for line in f:\n",
    "#             log += [json.loads(line)]\n",
    "            \n",
    "# runNums    = 0\n",
    "# for line in log:\n",
    "#     if line['time'] == [1]:\n",
    "#         runNums     += 1\n",
    "#         configIDs.add(line['config ID'][0])\n",
    "                \n",
    "# print('runNums: {} TotalLines: {}'.format(runNums,len(log)))\n",
    "\n",
    "# for config  in configIDs:\n",
    "#     varname = \"logs_of_\"+str(config)[-1]\n",
    "#     globals()[varname] = []\n",
    "#     logs.append(globals()[varname])\n",
    "    \n",
    "# for line in log:\n",
    "#     globals()[\"logs_of_\"+str(line['config ID'][0])[-1]].append(line)\n",
    "    \n",
    "# for (idx,log) in enumerate(logs):\n",
    "#     globals()[f\"df_{str(idx)}\"] = pd.DataFrame(log)\n",
    "    \n",
    "# timeline = df_1['time']\n",
    "# time_line = []\n",
    "\n",
    "# for t in timeline:\n",
    "#     time_line.append(t[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
